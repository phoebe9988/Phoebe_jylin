{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwtxSnnr3BqG"
      },
      "source": [
        "import keras\n",
        "from numpy import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, SimpleRNN,Conv1D, AveragePooling1D, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix,f1_score,recall_score,accuracy_score,precision_score,roc_auc_score,precision_recall_curve\n",
        "import lightgbm as lgb\n",
        "from lightgbm.sklearn import LGBMClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-LEf704VXtk",
        "outputId": "b5006ffe-6ff6-4ff9-9154-6d227e3a44c2"
      },
      "source": [
        "# install to see the progress bar\n",
        "#!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSYusp8z8WjP"
      },
      "source": [
        "#read file after train/test split  \n",
        "x_train=pd.read_csv('xtrain.csv')\n",
        "y_train=pd.read_csv('ytrain.csv')\n",
        "x_test=pd.read_csv('xtest.csv')\n",
        "y_test=pd.read_csv('ytest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZzM6ZaQ8aBO"
      },
      "source": [
        "#Dynamic features\n",
        "#PAY(X6-X11)\n",
        "pay_train = x_train[['X6','X7','X8','X9','X10','X11']]\n",
        "pay_test = x_test[['X6','X7','X8','X9','X10','X11']]\n",
        "#BILL_AMT(X12-X17)\n",
        "bill_amt_train = x_train[['X12','X13','X14','X15','X16','X17']]\n",
        "bill_amt_test = x_test[['X12','X13','X14','X15','X16','X17']]\n",
        "#PAY_AMT(X18-X23)\n",
        "pay_amt_train = x_train[['X18','X19','X20','X21','X22','X23']]\n",
        "pay_amt_test = x_test[['X18','X19','X20','X21','X22','X23']]\n",
        "#PAY\n",
        "pay_train = pay_train[pay_train.columns[::-1]] #Since pay0~pay6 are data from Sept. to Apr., so we'll have to feed in the data backwards to that it's in chronological order\n",
        "pay_test = pay_test[pay_test.columns[::-1]]\n",
        "#BILL_AMT\n",
        "bill_amt_train = bill_amt_train[bill_amt_train.columns[::-1]]\n",
        "bill_amt_test = bill_amt_test[bill_amt_test.columns[::-1]]\n",
        "#PAY_AMT\n",
        "pay_amt_train = pay_amt_train[pay_amt_train.columns[::-1]]\n",
        "pay_amt_test = pay_amt_test[pay_amt_test.columns[::-1]]\n",
        "#reshape train data\n",
        "#number of features\n",
        "nb_features=1\n",
        "#number of observing timepoints\n",
        "nb_times=6\n",
        "pay_train_time = np.zeros((len(pay_train), nb_times, nb_features*1))\n",
        "bill_amt_train_time = np.zeros((len(bill_amt_train), nb_times, nb_features*1))\n",
        "pay_amt_train_time = np.zeros((len(pay_amt_train), nb_times, nb_features*1))\n",
        "for i in range(0, nb_times):\n",
        "    pay_train_time[:,i,:] = pay_train.values[:, nb_features*i:nb_features*(i+1)]\n",
        "    bill_amt_train_time[:,i,:] = bill_amt_train.values[:, nb_features*i:nb_features*(i+1)]\n",
        "    pay_amt_train_time[:,i,:] = pay_amt_train.values[:, nb_features*i:nb_features*(i+1)]\n",
        "pay_test_time = np.zeros((len(pay_test), nb_times, nb_features*1)) \n",
        "bill_amt_test_time = np.zeros((len(bill_amt_test), nb_times, nb_features*1))\n",
        "pay_amt_test_time = np.zeros((len(pay_amt_test), nb_times, nb_features*1))\n",
        "for i in range(0, nb_times):\n",
        "    pay_test_time[:,i,:] = pay_test.values[:, nb_features*i:nb_features*(i+1)]\n",
        "    bill_amt_test_time[:,i,:] = bill_amt_test.values[:, nb_features*i:nb_features*(i+1)]\n",
        "    pay_amt_test_time[:,i,:] = pay_amt_test.values[:, nb_features*i:nb_features*(i+1)]\n",
        "#print(pay_train_time.shape) #checking the results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSkLph1lzq74",
        "outputId": "c05c99b0-ec95-4a3a-8633-affbd6c6b769"
      },
      "source": [
        "type( pay_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIJnP9wkzzMA"
      },
      "source": [
        "pay_train_ar=pd.DataFrame(pay_train).to_numpy()\n",
        "pay_test_ar=pd.DataFrame(pay_test).to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjUjQIdd984i"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar7l5N1uOJjn"
      },
      "source": [
        "def CNN(layer,neuron,fun):\n",
        "  model=Sequential()\n",
        "  # one layer CNN\n",
        "  model.add(Conv1D(neuron, 2, input_shape=(6,1))) # 2 means kernal size\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(fun))\n",
        "  # two layer CNN\n",
        "  if layer == 2 or 3:\n",
        "    model.add(Conv1D(neuron, 2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(fun))  \n",
        "  # three layer CNN\n",
        "  if layer == 3:\n",
        "    model.add(Conv1D(neuron, 2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(fun)) \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  callbacks = [EarlyStopping(monitor = 'val_loss', patience = 30)]\n",
        "  model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n",
        "  history1 = model.fit(pay_train_ar, y_train,validation_split=0.2,epochs = 50, batch_size = 512, callbacks = callbacks,verbose=0)\n",
        "  history2 = model.fit(bill_amt_train_time, y_train,validation_split=0.2,epochs = 50, batch_size = 512, callbacks = callbacks,verbose=0)\n",
        "  history3 = model.fit(pay_amt_train_time, y_train,validation_split=0.2,epochs = 50, batch_size = 512, callbacks = callbacks,verbose=0)\n",
        "  layer_name='output'\n",
        "  intermediate_layer_model=Model(inputs=model.input,outputs=(model.get_layer(layer_name).output))\n",
        "  # pay\n",
        "  intermediate_output=intermediate_layer_model.predict([pay_train_ar])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new1_train=pd.concat([x_train, intermediate_output], axis=1)\n",
        "  new1_train.rename(columns={0:'TSEF_PAY'}, inplace = True)\n",
        "\n",
        "  intermediate_output=intermediate_layer_model.predict([pay_test_ar])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new1_test=pd.concat([x_test, intermediate_output], axis=1)\n",
        "  new1_test.rename(columns={0:'TSEF_PAY'}, inplace = True)\n",
        "  #bill_amt\n",
        "  intermediate_output=intermediate_layer_model.predict([bill_amt_train_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new2_train=pd.concat([new1_train, intermediate_output], axis=1)\n",
        "  new2_train.rename(columns={0:'TSEF_BILL_AMT'}, inplace = True)\n",
        "\n",
        "  intermediate_output=intermediate_layer_model.predict([bill_amt_test_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new2_test=pd.concat([new1_test, intermediate_output], axis=1)\n",
        "  new2_test.rename(columns={0:'TSEF_BILL_AMT'}, inplace = True)\n",
        "  #pay_amt\n",
        "  intermediate_output=intermediate_layer_model.predict([pay_amt_train_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new3_train=pd.concat([new2_train, intermediate_output], axis=1)\n",
        "  new3_train.rename(columns={0:'TSEF_PAY_AMT'}, inplace = True)\n",
        "\n",
        "  intermediate_output=intermediate_layer_model.predict([pay_amt_test_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new3_test=pd.concat([new2_test, intermediate_output], axis=1)\n",
        "  new3_test.rename(columns={0:'TSEF_PAY_AMT'}, inplace = True)\n",
        "\n",
        "  return new3_train,new3_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kghq9EM1-ASa"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NadZkfPIK9VF"
      },
      "source": [
        "def RNN(layer,neuron,fun):\n",
        "  # one layer RNN\n",
        "  if layer ==1:\n",
        "    model=Sequential()\n",
        "    model.add(SimpleRNN(neuron, return_sequences=False, input_shape=(nb_times, nb_features*1),unroll=True)) \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(fun))\n",
        "  # two layer RNN\n",
        "  if layer == 2:\n",
        "    model=Sequential()\n",
        "    model.add(SimpleRNN(neuron, return_sequences=True, input_shape=(nb_times, nb_features*1),unroll=True)) \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(fun))\n",
        "    model.add(SimpleRNN(neuron,return_sequences=False,unroll=True)) \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(fun))\n",
        "  # three layer RNN\n",
        "  if layer == 3:\n",
        "    model=Sequential()\n",
        "    model.add(SimpleRNN(neuron, return_sequences=True, input_shape=(nb_times, nb_features*1),unroll=True)) \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(fun))\n",
        "    model.add(SimpleRNN(neuron,return_sequences=True,unroll=True)) \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(SimpleRNN(neuron,return_sequences=False ,unroll=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(fun))\n",
        "   \n",
        "  model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "  callbacks=[EarlyStopping(monitor = 'val_loss', patience=30)]\n",
        "  model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n",
        "  history1=model.fit(pay_train_time, y_train, epochs=50, validation_data=(pay_test_time, y_test), batch_size=512, callbacks=callbacks,verbose=0)\n",
        "  history2=model.fit(bill_amt_train_time, y_train, epochs=50, validation_data=(bill_amt_test_time, y_test), batch_size=512, callbacks=callbacks,verbose=0)\n",
        "  history3=model.fit(pay_amt_train_time, y_train, epochs=50, validation_data=(pay_amt_test_time, y_test), batch_size=512, callbacks=callbacks,verbose =0)\n",
        "  \n",
        "  layer_name='output'\n",
        "  intermediate_layer_model=Model(inputs=model.input,outputs=(model.get_layer(layer_name).output))\n",
        "  # pay\n",
        "  intermediate_output=intermediate_layer_model.predict([pay_train_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new1_train=pd.concat([x_train, intermediate_output], axis=1)\n",
        "  new1_train.rename(columns={0:'TSEF_PAY'}, inplace = True)\n",
        "\n",
        "  intermediate_output=intermediate_layer_model.predict([pay_test_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new1_test=pd.concat([x_test, intermediate_output], axis=1)\n",
        "  new1_test.rename(columns={0:'TSEF_PAY'}, inplace = True)\n",
        "  # bill_amt\n",
        "  intermediate_output=intermediate_layer_model.predict([bill_amt_train_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new2_train=pd.concat([new1_train, intermediate_output], axis=1)\n",
        "  new2_train.rename(columns={0:'TSEF_BILL_AMT'}, inplace = True)\n",
        "\n",
        "  intermediate_output=intermediate_layer_model.predict([bill_amt_test_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new2_test=pd.concat([new1_test, intermediate_output], axis=1)\n",
        "  new2_test.rename(columns={0:'TSEF_BILL_AMT'}, inplace = True)\n",
        "  # pay_amt\n",
        "  intermediate_output=intermediate_layer_model.predict([pay_amt_train_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new3_train=pd.concat([new2_train, intermediate_output], axis=1)\n",
        "  new3_train.rename(columns={0:'TSEF_PAY_AMT'}, inplace = True)\n",
        "  \n",
        "  intermediate_output=intermediate_layer_model.predict([pay_amt_test_time])\n",
        "  intermediate_output=pd.DataFrame(intermediate_output)\n",
        "  new3_test=pd.concat([new2_test, intermediate_output], axis=1)\n",
        "  new3_test.rename(columns={0:'TSEF_PAY_AMT'}, inplace = True)\n",
        "\n",
        "  return new3_train,new3_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdzA85t493eO"
      },
      "source": [
        "### LR "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT2E1GqNH4z_"
      },
      "source": [
        "def logistic(x_newtrain,x_newtest,result,fun,layer,neuron):\n",
        "  logreg = LogisticRegression( ).fit(x_newtrain, y_train)\n",
        "  logreg1 = LogisticRegression( ).fit(x_newtest, y_test)\n",
        "  y_prob = logreg.predict_proba(x_newtrain)[:,1]\n",
        "  y_prob1 = logreg.predict_proba(x_newtest)[:,1]\n",
        "  y_pred = logreg.predict(x_newtrain)\n",
        "  y_pred1 = logreg.predict(x_newtest)\n",
        "  # get the threshold of f1-score\n",
        "  best_thr1,f1_score_train= return_best_thr(y_train,y_prob)\n",
        "  best_thr2,f1_score_test= return_best_thr(y_test,y_prob1)\n",
        "  # get csv data form\n",
        "  new = pd.DataFrame.from_dict( {\"model\": [\"LR\"],\n",
        "                               \"FE_activation\":[fun],\n",
        "                               \"FE_layer\":[str(layer)],\n",
        "                               \"FE_neuron\":[str(neuron)],\n",
        "                               \"data\":[data],\n",
        "                               \"train_accuracy\":[accuracy_score(y_train,y_pred)],\n",
        "                               \"train_precision\":[precision_score(y_train,y_pred)],\n",
        "                               \"train_recall\":[recall_score(y_train,y_pred)],\n",
        "                               \"train_F1_score\":[f1_score_train],\n",
        "                               \"train_AUC\":[roc_auc_score(y_train, y_pred)],\n",
        "                               \"test_accuracy\":[accuracy_score(y_test, y_pred1)],\n",
        "                               \"test_precision\":[precision_score(y_test,y_pred1)],\n",
        "                               \"test_recall\":[recall_score(y_test,y_pred1)],\n",
        "                               \"test_F1_score\":[f1_score_test],\n",
        "                               \"test_AUC\":[roc_auc_score(y_test,y_pred1)]}) \n",
        "  result = result.append(new,ignore_index=True) \n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2j-eeu45kuh"
      },
      "source": [
        "## DT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dC8J1SX5kST"
      },
      "source": [
        "def DT(x_train,x_test,result,fun,layer,neuron):\n",
        "  for depth in tqdm(range(5,10,1)):\n",
        "    classifier = DecisionTreeClassifier(random_state=0, max_depth=depth)\n",
        "    classifier.fit(x_train, y_train)\n",
        "    \n",
        "    y_pred=classifier.predict(x_train)\n",
        "    y_prob=classifier.predict_proba(x_train)[:,1]\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_prob, pos_label=1)\n",
        "    AUC =round(auc(fpr, tpr),4)\n",
        "    y_pred1=classifier.predict(x_test)\n",
        "    y_prob1=classifier.predict_proba(x_test)[:,1]\n",
        "    fpr1, tpr1, thresholds1 = metrics.roc_curve(y_test, y_prob1, pos_label=1)\n",
        "    AUC1 =round(auc(fpr1, tpr1),4)\n",
        "    # get the threshold of f1-score\n",
        "    best_thr1,f1_score_train= return_best_thr(y_train,y_prob)\n",
        "    best_thr2,f1_score_test= return_best_thr(y_test,y_prob1)\n",
        "    # get csv data form\n",
        "    new = pd.DataFrame.from_dict( {\"model\": [\"DT\"],\n",
        "                                \"FE_activation\":[fun],\n",
        "                                \"FE_layer\":[str(layer)],\n",
        "                                \"FE_neuron\":[str(neuron)],\n",
        "                                \"max_depth\":[str(depth)],             \n",
        "                                \"data\":[data],\n",
        "                                \"train_accuracy\":[metrics.accuracy_score(y_train, y_pred)],\n",
        "                                \"train_precision\":[metrics.precision_score(y_train, y_pred)],\n",
        "                                \"train_recall\":[metrics.recall_score(y_train, y_pred)],\n",
        "                                \"train_F1_score\":[f1_score_train],\n",
        "                                \"train_AUC\":[str(AUC)],\n",
        "                                \"test_accuracy\":[metrics.accuracy_score(y_test, y_pred1)],\n",
        "                                \"test_precision\":[metrics.precision_score(y_test, y_pred1)],\n",
        "                                \"test_recall\":[metrics.recall_score(y_test, y_pred1)],\n",
        "                                \"test_F1_score\":[f1_score_test],\n",
        "                                \"test_AUC\":[str(AUC1)]}) \n",
        "    result = result.append(new,ignore_index=True) \n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38WRdTv7zYw"
      },
      "source": [
        "## LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRzXsdMr5Jt8"
      },
      "source": [
        "def LGBM(x_train,x_test,result,fun,layer,neuron):\n",
        "  leaves = [28,29,30,31,32,33,34,35,36,37,38,39,40,41,42]\n",
        "  l=0\n",
        "  for depth in tqdm(range (5,8,1)):\n",
        "    for count in range (5):\n",
        "      classifier= lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=leaves[l], max_depth=depth, learning_rate=0.5, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.05, min_child_weight=0.9, min_child_samples=20, subsample=1.0, \n",
        "                                    subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=- 1, silent=True, importance_type='split')\n",
        "      classifier.fit(x_train, y_train)\n",
        "      y_pred=classifier.predict(x_train)\n",
        "      y_prob=classifier.predict_proba(x_train)[:,1]\n",
        "      fpr, tpr, thresholds = metrics.roc_curve(y_train, y_prob, pos_label=1)\n",
        "      AUC =round(auc(fpr, tpr),4)\n",
        "      y_pred1=classifier.predict(x_test)\n",
        "      y_prob1=classifier.predict_proba(x_test)[:,1]\n",
        "      fpr1, tpr1, thresholds1 = metrics.roc_curve(y_test, y_prob1, pos_label=1)\n",
        "      AUC1 =round(auc(fpr1, tpr1),4)\n",
        "      # get the threshold of f1-score\n",
        "      best_thr1,f1_score_train= return_best_thr(y_train,y_prob)\n",
        "      best_thr2,f1_score_test= return_best_thr(y_test,y_prob1)\n",
        "      # get csv data form\n",
        "      new = pd.DataFrame.from_dict( {\"model\": [\"LGBM\"],\n",
        "                                    \"FE_activation\":[fun],\n",
        "                                    \"FE_layer\":[str(layer)],\n",
        "                                    \"FE_neuron\":[str(neuron)],\n",
        "                                    \"max_depth\":[str(depth)],\n",
        "                                    \"num_leaves\":[str(leaves[l])],          \n",
        "                                    \"data\":[data],\n",
        "                                    \"train_accuracy\":[metrics.accuracy_score(y_train, y_pred)],\n",
        "                                    \"train_precision\":[metrics.precision_score(y_train, y_pred)],\n",
        "                                    \"train_recall\":[metrics.recall_score(y_train, y_pred)],\n",
        "                                    \"train_F1_score\":[f1_score_train],\n",
        "                                    \"train_AUC\":[str(AUC)],\n",
        "                                    \"test_accuracy\":[metrics.accuracy_score(y_test, y_pred1)],\n",
        "                                    \"test_precision\":[metrics.precision_score(y_test, y_pred1)],\n",
        "                                    \"test_recall\":[metrics.recall_score(y_test, y_pred1)],\n",
        "                                    \"test_F1_score\":[f1_score_test],\n",
        "                                    \"test_AUC\":[str(AUC1)]}) \n",
        "      \n",
        "      result = result.append(new,ignore_index=True) \n",
        "      l=l+1\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyYqQ0RApji0"
      },
      "source": [
        "## NN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKN2JPz-d_xY"
      },
      "source": [
        "def NN(x_train,x_test,nn_layer,result,fun,layer,neuron,d,function,data):\n",
        "  sequence = [0.1,0.2,0.3,0.4,0.5]\n",
        "  for l in sequence:\n",
        "    # NN layer 1 \n",
        "    model = Sequential()\n",
        "    model.add(Dense(128,input_dim=d))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(function))\n",
        "    model.add(Dropout(l))\n",
        "    # NN layer 2\n",
        "    if nn_layer == 2 or 3:\n",
        "      model.add(Dense(128))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(Activation(function))\n",
        "      model.add(Dropout(l))\n",
        "    # NN layer 3\n",
        "    if nn_layer ==3:\n",
        "      model.add(Dense(128))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(Activation(function))\n",
        "      model.add(Dropout(l))\n",
        "    model.add(Dense(1, name='output'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    callbacks=[EarlyStopping(monitor = 'val_loss', patience=30)]\n",
        "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n",
        "    history=model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), batch_size=512, callbacks=callbacks,verbose=0)\n",
        "    y_pred = model.predict(x_train)\n",
        "    y_prob = model.predict_proba(x_train)\n",
        "    # get the threshold of f1-score\n",
        "    best_thr1,f1_score_train= return_best_thr(y_train,y_prob)\n",
        "    for i in range(len(y_pred)):\n",
        "      if y_pred[i] > best_thr1:\n",
        "        y_pred[i] =  1\n",
        "      else:\n",
        "        y_pred[i] = 0\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    \n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_prob, pos_label=1)\n",
        "    AUC = round(auc(fpr, tpr),4)\n",
        "    acc = metrics.accuracy_score(y_train,y_pred)\n",
        "    pre = metrics.precision_score(y_train,y_pred)\n",
        "    rec = metrics.recall_score(y_train,y_pred)\n",
        "    F1 = 2*(pre*rec)/(pre+rec)\n",
        "    y_pred1=model.predict(x_test)\n",
        "    y_prob1 = model.predict_proba(x_test)\n",
        "    # get the threshold of f1-score\n",
        "    best_thr2,f1_score_test= return_best_thr(y_test,y_prob1)\n",
        "    for i in range(len(y_pred1)):\n",
        "      if y_pred1[i]> best_thr2:\n",
        "        y_pred1[i] = 1\n",
        "      else:\n",
        "        y_pred1[i] = 0    \n",
        "    \n",
        "    fpr1, tpr1, thresholds1 = metrics.roc_curve(y_test, y_prob1, pos_label=1)\n",
        "    AUC1 = round(auc(fpr1, tpr1),4)\n",
        "    acc1 = metrics.accuracy_score(y_test,y_pred1)\n",
        "    pre1 = metrics.precision_score(y_test,y_pred1)\n",
        "    rec1 = metrics.recall_score(y_test,y_pred1)\n",
        "    F11 = 2*(pre1*rec1)/(pre1+rec1) \n",
        "    # get csv data form\n",
        "    new = pd.DataFrame.from_dict( {\"model\": [\"NN\"],\n",
        "                                \"FE_activation\":[fun],\n",
        "                                \"FE_layer\":[str(layer)],\n",
        "                                \"FE_neuron\":[str(neuron)],\n",
        "                                \"NN_layer\":[str(nn_layer)],\n",
        "                                \"Dropout\":[str(l)],\n",
        "                                \"nn activation function\":[function],            \n",
        "                                \"data\":[data],\n",
        "                                \"train_accuracy\":[acc],\n",
        "                                \"train_precision\":[pre],\n",
        "                                \"train_recall\":[rec],\n",
        "                                \"train_F1_score\":[F1],\n",
        "                                \"train_AUC\":[str(AUC)],\n",
        "                                \"test_accuracy\":[acc1],\n",
        "                                \"test_precision\":[pre1],\n",
        "                                \"test_recall\":[rec1],\n",
        "                                \"test_F1_score\":[F11],\n",
        "                                \"test_AUC\":[str(AUC1)]}) \n",
        "    result = result.append(new,ignore_index=True) \n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYU4ez2wk1WM"
      },
      "source": [
        "## threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj-aX3Umk0jl"
      },
      "source": [
        "# dynamic select F1-score thershold\n",
        "def return_best_thr(y_true, y_pred):\n",
        "    precs, recs, thrs = precision_recall_curve(y_true, y_pred)\n",
        "    f1s = 2 * precs * recs / (precs + recs)\n",
        "    f1s = f1s[:-1]\n",
        "    thrs = thrs[~np.isnan(f1s)]\n",
        "    f1s = f1s[~np.isnan(f1s)]\n",
        "    best_thr = thrs[np.argmax(f1s)]\n",
        "    f1_score = np.max(f1s)\n",
        "    return best_thr,f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWUzapneAH07"
      },
      "source": [
        "## core function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd5Wp7VLqVer",
        "outputId": "10ec35bf-4b6a-4fd8-8dd7-08ffebd72466"
      },
      "source": [
        "# check shape (24000,87) \n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 87)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVzHfWQC3Hqs",
        "outputId": "0cd78ab8-8777-41fe-f19d-569255d55019"
      },
      "source": [
        "# Input space\n",
        "data = input(\"Input data: XB/XTR \")\n",
        "if data==\"XB\":\n",
        "  state =\"original\"\n",
        "else:\n",
        "  state = input(\"Input state: CNN/ RNN \")\n",
        "  fun = input(\"Input CNN or RNN activation function: relu/ tanh \")\n",
        "model = input(\"Input model: LR/DT/LGBM/NN \")\n",
        "if model == \"NN\":\n",
        "  nn_fun= input(\"Input NN activaiton function: relu/tanh \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data: XB/XTR XTR\n",
            "Input state: CNN/ RNN CNN\n",
            "Input CNN or RNN activation function: relu/ tanh relu\n",
            "Input model: LR/DT/LGBM/NN LR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KznEFw77HNVh",
        "outputId": "768e0e12-1832-4917-9387-db3bd669191b"
      },
      "source": [
        "# main function\n",
        "result = pd.DataFrame(columns=['model',\"FE_activation\",\"FE_layer\",\"FE_neuron\",'data','train_accuracy','train_precision','train_recall','train_F1_score','train_AUC',\n",
        "                               'test_accuracy','test_precision','test_recall','test_F1_score','test_AUC'])\n",
        "start = time.clock()\n",
        "if state ==\"original\": #XB\n",
        "  fun =\"\"\n",
        "  layer=\"\"\n",
        "  neuron=\"\"\n",
        "  if model ==\"LR\":\n",
        "    result =logistic(x_train,x_test,result,fun,layer,neuron)\n",
        "  if model ==\"DT\":\n",
        "    result = DT(x_train,x_test,result,fun,layer,neuron)\n",
        "  if model ==\"LGBM\":\n",
        "    result = LGBM(x_train,x_test,result,fun,layer,neuron)\n",
        "  if model ==\"NN\":\n",
        "    for nn_layer in range (1,4):\n",
        "      fun =\"\"\n",
        "      layer=\"\"\n",
        "      neuron=\"\"\n",
        "      data=\"XB\"\n",
        "      d = 87\n",
        "      result = NN(x_train,x_test,nn_layer,result,fun,layer,neuron,d,nn_fun,data)\n",
        "    \n",
        "elif state ==\"CNN\": #CNN\n",
        "  for layer in tqdm(range (1,4)):\n",
        "    neuron =1\n",
        "    while neuron !=256:\n",
        "      new3_train,new3_test = CNN(layer,neuron,fun)      \n",
        "      \n",
        "      if data==\"XTR\":\n",
        "        x_newtrain=new3_train\n",
        "        x_newtest= new3_test\n",
        "        if model==\"LR\":\n",
        "          result = logistic(x_newtrain,x_newtest,result,fun,layer,neuron)\n",
        "        if model==\"DT\":\n",
        "          result = DT(x_newtrain,x_newtest,result,fun,layer,neuron)\n",
        "        if model==\"LGBM\":\n",
        "          result = LGBM(x_newtrain,x_newtest,result,fun,layer,neuron)\n",
        "        if model==\"NN\":\n",
        "          d=90\n",
        "          for nn_layer in range (1,4):\n",
        "            x_newtrain=new3_train\n",
        "            x_newtest= new3_test\n",
        "            result = NN(x_newtrain,x_newtest,nn_layer,result,fun,layer,neuron,d,nn_fun,data)\n",
        "      \n",
        "      neuron = neuron*2\n",
        "     \n",
        "elif state ==\"RNN\": #RNN  \n",
        "  for layer in tqdm(range(1,4)):\n",
        "    neuron =1\n",
        "    while neuron !=256:\n",
        "      new3_train,new3_test = RNN(layer,neuron,fun)      \n",
        "      \n",
        "      if data==\"XTR\":\n",
        "        x_newtrain=new3_train\n",
        "        x_newtest= new3_test\n",
        "        if model==\"LR\":\n",
        "          result = logistic(x_newtrain,x_newtest,result,fun,layer,neuron)\n",
        "        if model==\"DT\":\n",
        "          result = DT(x_newtrain,x_newtest,result,fun,layer,neuron)\n",
        "        if model==\"LGBM\":\n",
        "          result = LGBM(x_newtrain,x_newtest,result,fun,layer,neuron)\n",
        "        if model==\"NN\":\n",
        "          d=90\n",
        "          for nn_layer in range (1,4):\n",
        "            x_newtrain=new3_train\n",
        "            x_newtest= new3_test\n",
        "            result = NN(x_newtrain,x_newtest,nn_layer,result,fun,layer,neuron,d,nn_fun,data)\n",
        "      neuron = neuron*2\n",
        "end = time.clock()  \n",
        "print(\"End, Time:\",end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_7 (Conv1D)            (None, 5, 1)              3         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 5, 1)              4         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5, 1)              0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 4, 1)              3         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4, 1)              4         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4, 1)              0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 19\n",
            "Trainable params: 15\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0188f5f874cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mneuron\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mnew3_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew3_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"XTR\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-01997f33788b>\u001b[0m in \u001b[0;36mCNN\u001b[0;34m(layer, neuron, fun)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpay_train_ar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mhistory2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbill_amt_train_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mhistory3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpay_amt_train_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgoNd0LPVOUf"
      },
      "source": [
        "### Storing the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "M4MbUMU65M7u",
        "outputId": "775830d0-d49d-4e29-88a2-01166880e6fe"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>FE_activation</th>\n",
              "      <th>FE_layer</th>\n",
              "      <th>FE_neuron</th>\n",
              "      <th>data</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>train_precision</th>\n",
              "      <th>train_recall</th>\n",
              "      <th>train_F1_score</th>\n",
              "      <th>train_AUC</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_F1_score</th>\n",
              "      <th>test_AUC</th>\n",
              "      <th>NN_layer</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>nn activation function</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.829958</td>\n",
              "      <td>0.664244</td>\n",
              "      <td>0.452055</td>\n",
              "      <td>0.537983</td>\n",
              "      <td>0.8078</td>\n",
              "      <td>0.811000</td>\n",
              "      <td>0.634279</td>\n",
              "      <td>0.421014</td>\n",
              "      <td>0.506098</td>\n",
              "      <td>0.756</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.830833</td>\n",
              "      <td>0.713419</td>\n",
              "      <td>0.380327</td>\n",
              "      <td>0.496153</td>\n",
              "      <td>0.8119</td>\n",
              "      <td>0.815333</td>\n",
              "      <td>0.685286</td>\n",
              "      <td>0.364493</td>\n",
              "      <td>0.475875</td>\n",
              "      <td>0.7749</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>0.651795</td>\n",
              "      <td>0.455860</td>\n",
              "      <td>0.536498</td>\n",
              "      <td>0.7945</td>\n",
              "      <td>0.814167</td>\n",
              "      <td>0.637022</td>\n",
              "      <td>0.446377</td>\n",
              "      <td>0.524925</td>\n",
              "      <td>0.7657</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.823792</td>\n",
              "      <td>0.689834</td>\n",
              "      <td>0.355023</td>\n",
              "      <td>0.468785</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.816333</td>\n",
              "      <td>0.700288</td>\n",
              "      <td>0.352174</td>\n",
              "      <td>0.468660</td>\n",
              "      <td>0.7705</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.823083</td>\n",
              "      <td>0.689992</td>\n",
              "      <td>0.348935</td>\n",
              "      <td>0.463482</td>\n",
              "      <td>0.7901</td>\n",
              "      <td>0.817167</td>\n",
              "      <td>0.709630</td>\n",
              "      <td>0.347101</td>\n",
              "      <td>0.466180</td>\n",
              "      <td>0.7721</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.836958</td>\n",
              "      <td>0.765520</td>\n",
              "      <td>0.368341</td>\n",
              "      <td>0.497367</td>\n",
              "      <td>0.8377</td>\n",
              "      <td>0.807167</td>\n",
              "      <td>0.677266</td>\n",
              "      <td>0.308696</td>\n",
              "      <td>0.424092</td>\n",
              "      <td>0.7656</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.830750</td>\n",
              "      <td>0.717883</td>\n",
              "      <td>0.374239</td>\n",
              "      <td>0.491996</td>\n",
              "      <td>0.8181</td>\n",
              "      <td>0.811667</td>\n",
              "      <td>0.678063</td>\n",
              "      <td>0.344928</td>\n",
              "      <td>0.457253</td>\n",
              "      <td>0.7687</td>\n",
              "      <td>3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.830792</td>\n",
              "      <td>0.699100</td>\n",
              "      <td>0.399163</td>\n",
              "      <td>0.508175</td>\n",
              "      <td>0.816</td>\n",
              "      <td>0.814000</td>\n",
              "      <td>0.670984</td>\n",
              "      <td>0.375362</td>\n",
              "      <td>0.481413</td>\n",
              "      <td>0.7653</td>\n",
              "      <td>3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.828583</td>\n",
              "      <td>0.679222</td>\n",
              "      <td>0.411720</td>\n",
              "      <td>0.512675</td>\n",
              "      <td>0.812</td>\n",
              "      <td>0.812167</td>\n",
              "      <td>0.655980</td>\n",
              "      <td>0.385507</td>\n",
              "      <td>0.485623</td>\n",
              "      <td>0.7686</td>\n",
              "      <td>3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>NN</td>\n",
              "      <td>tanh</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>XTR</td>\n",
              "      <td>0.822583</td>\n",
              "      <td>0.623944</td>\n",
              "      <td>0.477930</td>\n",
              "      <td>0.541263</td>\n",
              "      <td>0.8065</td>\n",
              "      <td>0.805333</td>\n",
              "      <td>0.604126</td>\n",
              "      <td>0.445652</td>\n",
              "      <td>0.512927</td>\n",
              "      <td>0.7652</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>240 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    model FE_activation FE_layer  ... NN_layer Dropout  nn activation function\n",
              "0      NN          tanh        1  ...        1     0.1                    tanh\n",
              "1      NN          tanh        1  ...        1     0.2                    tanh\n",
              "2      NN          tanh        1  ...        1     0.3                    tanh\n",
              "3      NN          tanh        1  ...        1     0.4                    tanh\n",
              "4      NN          tanh        1  ...        1     0.5                    tanh\n",
              "..    ...           ...      ...  ...      ...     ...                     ...\n",
              "235    NN          tanh        2  ...        3     0.1                    tanh\n",
              "236    NN          tanh        2  ...        3     0.2                    tanh\n",
              "237    NN          tanh        2  ...        3     0.3                    tanh\n",
              "238    NN          tanh        2  ...        3     0.4                    tanh\n",
              "239    NN          tanh        2  ...        3     0.5                    tanh\n",
              "\n",
              "[240 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8FOOgRCAZZK"
      },
      "source": [
        "result.to_csv('XTR_RNN_tanh_NN_relu_tmp.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
